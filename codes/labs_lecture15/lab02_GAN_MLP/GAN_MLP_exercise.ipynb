{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D0jesoktYdKv"
   },
   "source": [
    "# Lab 02 : Vanilla GAN with MLP - exercise\n",
    "\n",
    "The goal is to implement a GAN architecture with MLPs to generate new MNIST images.</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2572,
     "status": "ok",
     "timestamp": 1649158441713,
     "user": {
      "displayName": "Xavier Bresson",
      "userId": "14103767471123103792"
     },
     "user_tz": -480
    },
    "id": "yQkNjE9tYdKy",
    "outputId": "8d4098ef-1374-4c0f-86e5-674d324e6d4f"
   },
   "outputs": [],
   "source": [
    "# For Google Colaboratory\n",
    "import sys, os\n",
    "if 'google.colab' in sys.modules:\n",
    "    # mount google drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    path_to_file = '/content/gdrive/My Drive/CS4243_codes/codes/labs_lecture15/lab02_GAN_MLP'\n",
    "    print(path_to_file)\n",
    "    # move to Google Drive directory\n",
    "    os.chdir(path_to_file)\n",
    "    !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1649158441713,
     "user": {
      "displayName": "Xavier Bresson",
      "userId": "14103767471123103792"
     },
     "user_tz": -480
    },
    "id": "ERQgahj9YdKz"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import utils\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pTE_79QTVtx1"
   },
   "source": [
    "### GPU is required to train GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1649158441714,
     "user": {
      "displayName": "Xavier Bresson",
      "userId": "14103767471123103792"
     },
     "user_tz": -480
    },
    "id": "ZbjnZcmbYdKz",
    "outputId": "a24cf2c5-add9-4a64-857d-b4a5dd30457e"
   },
   "outputs": [],
   "source": [
    "device= torch.device(\"cuda\")\n",
    "#device= torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1649158441714,
     "user": {
      "displayName": "Xavier Bresson",
      "userId": "14103767471123103792"
     },
     "user_tz": -480
    },
    "id": "x11IwMXRYdK0"
   },
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.CRITICAL) # remove warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ju92i3CYdK1"
   },
   "source": [
    "### MNIST dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 780,
     "status": "ok",
     "timestamp": 1649158442490,
     "user": {
      "displayName": "Xavier Bresson",
      "userId": "14103767471123103792"
     },
     "user_tz": -480
    },
    "id": "750I1YxrYdK1",
    "outputId": "dead94f5-31c4-4ad8-8e15-9217342c796d"
   },
   "outputs": [],
   "source": [
    "from utils import check_mnist_dataset_exists\n",
    "data_path=check_mnist_dataset_exists()\n",
    "\n",
    "train_data=torch.load(data_path+'mnist/train_data.pt')\n",
    "train_label=torch.load(data_path+'mnist/train_label.pt')\n",
    "print(train_data.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TitZR-3YsDBW"
   },
   "source": [
    "### Network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1649158442490,
     "user": {
      "displayName": "Xavier Bresson",
      "userId": "14103767471123103792"
     },
     "user_tz": -480
    },
    "id": "2N0XCCvjsDBX"
   },
   "outputs": [],
   "source": [
    "# Global constants\n",
    "# n : nb of pixels along each spatial dimension\n",
    "# dz : latent dimension\n",
    "# d : hidden dimension\n",
    "# b : batch size\n",
    "n = train_data.size(1)\n",
    "dz = n\n",
    "d = 32* (n//4)**2 # hidden dimension is a function of image size\n",
    "b = 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1649158442491,
     "user": {
      "displayName": "Xavier Bresson",
      "userId": "14103767471123103792"
     },
     "user_tz": -480
    },
    "id": "3nV6N-9PYdK2",
    "outputId": "698485a8-6dcd-459c-8164-65713e7dfa79"
   },
   "outputs": [],
   "source": [
    "# Define the generator and discriminator networks\n",
    "class generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(generator, self).__init__()\n",
    "        # COMPLETE HERE\n",
    "        self.linear1 = \n",
    "        self.bn1 = \n",
    "        self.linear2 = \n",
    "        self.bn2 = \n",
    "        self.linear3 = \n",
    "    def forward(self, z): \n",
    "        # COMPLETE HERE\n",
    "        g_z = \n",
    "        return g_z\n",
    "\n",
    "class discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(discriminator, self).__init__()\n",
    "        # COMPLETE HERE\n",
    "        self.linear1 = \n",
    "        self.bn1 = \n",
    "        self.linear2 = \n",
    "        self.bn2 = \n",
    "        self.linear3 = \n",
    "    def forward(self, h): \n",
    "        # COMPLETE HERE\n",
    "        d_h = \n",
    "        return d_h\n",
    "\n",
    "# Instantiate the network\n",
    "net_g = generator()\n",
    "net_g = net_g.to(device)\n",
    "print(net_g)\n",
    "utils.display_num_param(net_g) \n",
    "net_d = discriminator()\n",
    "net_d = net_d.to(device)\n",
    "print(net_d)\n",
    "utils.display_num_param(net_d) \n",
    "\n",
    "# Test the forward pass, backward pass and gradient update with a single batch\n",
    "init_lr = 0.001\n",
    "optimizer_g = torch.optim.Adam(net_g.parameters(), lr=init_lr)\n",
    "optimizer_d = torch.optim.Adam(net_d.parameters(), lr=init_lr)\n",
    "\n",
    "b = 10\n",
    "idx = torch.LongTensor(b).random_(0,60000)\n",
    "x_real = train_data[idx,:,:].view(b,-1).to(device) # [b, n**2]\n",
    "print(x_real.size())\n",
    "\n",
    "z = torch.rand(b, dz).to(device) # [b, dz]\n",
    "print(z.size())\n",
    "\n",
    "p_one = torch.ones(b, 1).to(device)\n",
    "p_zero = torch.zeros(b, 1).to(device)\n",
    "\n",
    "# update g\n",
    "optimizer_g.zero_grad()\n",
    "x_fake = net_g(z) # [b, 1, n, n]\n",
    "p_fake = net_d(x_fake) # [b, 1]\n",
    "print(x_fake.size(), p_fake.size())\n",
    "loss_fake = nn.BCELoss()(p_fake, p_one)\n",
    "loss = loss_fake\n",
    "loss.backward()\n",
    "optimizer_g.step()\n",
    "\n",
    "# update d\n",
    "optimizer_d.zero_grad()\n",
    "x_fake = net_g(z) # [b, 1, n, n]\n",
    "p_fake = net_d(x_fake) # [b, 1]\n",
    "p_real = net_d(x_real.view(-1,n,n).unsqueeze(1)) # [b, 1]\n",
    "print(x_fake.size(), p_fake.size(), p_real.size())\n",
    "loss_real = nn.BCELoss()(p_real, p_one)\n",
    "loss_fake = nn.BCELoss()(p_fake, p_zero)\n",
    "loss = loss_real + loss_fake\n",
    "loss.backward()\n",
    "optimizer_d.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "tvuWro5BYdK4",
    "outputId": "4296738e-639d-4d2b-d67a-282e38c8926a",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Training loop\n",
    "net_g = generator()\n",
    "net_g = net_g.to(device)\n",
    "print(net_g)\n",
    "utils.display_num_param(net_g) \n",
    "net_d = discriminator()\n",
    "net_d = net_d.to(device)\n",
    "print(net_d)\n",
    "utils.display_num_param(net_d) \n",
    "\n",
    "# Optimizer\n",
    "init_lr = 0.0002\n",
    "optimizer_g = torch.optim.Adam(net_g.parameters(), lr=init_lr, betas=(0.5, 0.999))\n",
    "optimizer_d = torch.optim.Adam(net_d.parameters(), lr=init_lr, betas=(0.5, 0.999))\n",
    "\n",
    "nb_batch = 200 # GPU # Nb of mini-batches per epoch\n",
    "#nb_batch = 20 # CPU # Nb of mini-batches per epoch\n",
    "b = 64  # Batch size\n",
    "\n",
    "p_one = torch.ones(b, 1).to(device)\n",
    "p_zero = torch.zeros(b, 1).to(device)\n",
    "\n",
    "start=time.time()\n",
    "for epoch in range(50):\n",
    "\n",
    "    running_loss_d = 0.0\n",
    "    running_loss_g = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for _ in range(nb_batch):\n",
    "        \n",
    "        # FORWARD AND BACKWARD PASS\n",
    "        idx = torch.LongTensor(b).random_(0,60000)\n",
    "        x_real = train_data[idx,:,:].view(b,-1).to(device) # [b, n**2]\n",
    "        z = torch.rand(b, dz).to(device) # Uniform distribution # [b, dz]\n",
    "        \n",
    "        # update d\n",
    "        optimizer_d.zero_grad()\n",
    "        x_fake = net_g(z) # [b, 1, n, n]\n",
    "        p_fake = net_d(x_fake) # [b, 1]\n",
    "        p_real = net_d(x_real.view(-1,n,n).unsqueeze(1)) # [b, 1]\n",
    "        loss_real = nn.BCELoss()(p_real, p_one)\n",
    "        loss_fake = nn.BCELoss()(p_fake, p_zero)\n",
    "        loss = loss_real + loss_fake\n",
    "        loss_d = loss.detach().item()\n",
    "        loss.backward()\n",
    "        optimizer_d.step()\n",
    "        \n",
    "        # update g\n",
    "        optimizer_g.zero_grad()\n",
    "        x_fake = net_g(z) # [b, 1, n, n]\n",
    "        p_fake = net_d(x_fake) # [b, 1]\n",
    "        loss_fake = nn.BCELoss()(p_fake, p_one)\n",
    "        loss = loss_fake\n",
    "        loss_g = loss.detach().item()\n",
    "        loss.backward()\n",
    "        optimizer_g.step()\n",
    "\n",
    "        # COMPUTE STATS\n",
    "        running_loss_d += loss_d\n",
    "        running_loss_g += loss_g\n",
    "        num_batches += 1        \n",
    "    \n",
    "    # AVERAGE STATS THEN DISPLAY\n",
    "    total_loss_d = running_loss_d/ num_batches\n",
    "    total_loss_g = running_loss_g/ num_batches\n",
    "    elapsed = (time.time()-start)/60\n",
    "    print('epoch=',epoch, '\\t time=', elapsed,'min', '\\t lr=', init_lr  ,'\\t loss_d=', total_loss_d ,'\\t loss_g=', total_loss_g )\n",
    "\n",
    "    if not epoch%5:\n",
    "        plt.imshow(x_fake.view(b,n,n).detach().cpu()[0,:,:], cmap='gray'); plt.show() \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pT0g6UC0YdK5",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Generate a few images\n",
    "b = 10\n",
    "z = torch.rand(b, dz) # Uniform distribution \n",
    "z = z.to(device)\n",
    "x_new = net_g(z).view(b,n,n).detach().cpu()\n",
    "for k in range(b):\n",
    "    plt.imshow(x_new[k,:,:], cmap='gray'); plt.show() \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Hw31504YdK6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "GAN_MLP_solution.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
