{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 01 : Point Cloud Classification - exercise\n",
    "\n",
    "The goal is to implement an architecture that classifies point clouds.</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Google Colaboratory\n",
    "import sys, os\n",
    "if 'google.colab' in sys.modules:\n",
    "    # mount google drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    path_to_file = '/content/gdrive/My Drive/CS4243_codes/codes/labs_lecture13'\n",
    "    print(path_to_file)\n",
    "    # move to Google Drive directory\n",
    "    os.chdir(path_to_file)\n",
    "    !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import utils\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device= torch.device(\"cuda\")\n",
    "device= torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "from torchvision.transforms import ToTensor\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.CRITICAL) # remove warnings\n",
    "\n",
    "# Import 5 object types\n",
    "ob_size = 11\n",
    "objects = torch.zeros(5,ob_size,ob_size)\n",
    "nb_class_objects = 5\n",
    "for k in range(nb_class_objects):\n",
    "    objects[k,:,:] = 1-ToTensor()(Image.open('objects/obj'+str(k+1)+'.tif'))[0,:,:]\n",
    "print(objects.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define the bounding boxes w.r.t. object type\n",
    "def obj_legend(label):\n",
    "    if label==0:\n",
    "        color = 'r'; legend = 'Triangle'\n",
    "    elif label==1:\n",
    "        color = 'b'; legend = 'Cross'\n",
    "    elif label==2:\n",
    "        color = 'g'; legend = 'Star'\n",
    "    elif label==3:\n",
    "        color = 'y'; legend = 'Square'\n",
    "    elif label==4:\n",
    "        color = 'm'; legend = 'Ring'\n",
    "    return color, legend\n",
    "\n",
    "# Global constants\n",
    "# im_size = image size  \n",
    "# ob_size = object size\n",
    "# batch_size = batch size\n",
    "# nb_object_classes = number of object classes (we have 5 classes)\n",
    "im_size = 28 \n",
    "batch_size = 2\n",
    "nb_object_classes = 5\n",
    "nb_points = 35 # min=41 max=66\n",
    "\n",
    "# Function that generate a batch of training data\n",
    "def generate_batch_data(im_size, ob_size, batch_size, nb_points, nb_object_classes):\n",
    "    batch_images = torch.zeros(batch_size,im_size,im_size)\n",
    "    batch_points = torch.zeros(batch_size,nb_points,2)\n",
    "    batch_labels = torch.zeros(batch_size)\n",
    "    for b in range(batch_size):\n",
    "        image = torch.zeros(im_size,im_size) \n",
    "        class_object = torch.LongTensor(1).random_(0,nb_object_classes)        \n",
    "        offset = (ob_size-1)// 2 + 0\n",
    "        coord_objects = torch.LongTensor(2).random_(offset,im_size-offset)\n",
    "        # coord_objects[0] = x-coordinate,  coord_objects[1] = y-coordinate\n",
    "        image[coord_objects[1]-offset:coord_objects[1]-offset+ob_size,coord_objects[0]-offset:coord_objects[0]-offset+ob_size] = objects[class_object,:,:]\n",
    "        # find x,y s.t. image[y,x]=0.5\n",
    "        obj_yx = torch.Tensor(plt.contour(image, [0.5]).collections[0].get_paths()[0].vertices); plt.clf() \n",
    "        obj_yx[:,[0,1]] = obj_yx[:,[1,0]]\n",
    "        if class_object==4: # get the interior for the ring shape\n",
    "            obj_yx_tmp = torch.Tensor(plt.contour(image, [0.5]).collections[0].get_paths()[1].vertices); plt.clf() \n",
    "            obj_yx_tmp[:,[0,1]] = obj_yx_tmp[:,[1,0]]\n",
    "            obj_yx = torch.cat((obj_yx,obj_yx_tmp),dim=0)\n",
    "        nb_yx_pts = obj_yx.size(0)\n",
    "        if nb_yx_pts>=nb_points:\n",
    "            idx_perm = torch.randperm(nb_yx_pts)[:nb_points]\n",
    "            obj_yx = obj_yx[idx_perm,:]\n",
    "        else: # in case of plt.contour does not extract enough data points\n",
    "            obj_yx = obj_yx.repeat_interleave(nb_points//nb_yx_pts+1,dim=0)[:nb_points]\n",
    "        batch_images[b,:,:] = image\n",
    "        batch_points[b,:,:] = obj_yx\n",
    "        batch_labels[b] = class_object\n",
    "    return batch_images, batch_points, batch_labels\n",
    "\n",
    "# Plot a mini-batch of images\n",
    "batch_images, batch_points, batch_labels = generate_batch_data(im_size, ob_size, batch_size, nb_points, nb_object_classes)\n",
    "print(batch_images.size())\n",
    "print(batch_points.size())\n",
    "print(batch_labels.size())\n",
    "for b in range(batch_size):\n",
    "    #plt.imshow(batch_images[b,:,:], cmap='gray')\n",
    "    plt.imshow(torch.zeros(im_size,im_size), cmap='gray')\n",
    "    color, legend = obj_legend(batch_labels[b])\n",
    "    plt.scatter(batch_points[b,:,1],batch_points[b,:,0],marker='+',color=color,label=legend)\n",
    "    plt.legend(loc='best')\n",
    "    plt.colorbar()\n",
    "    plt.title('Point Cloud')\n",
    "    #plt.axis('off')\n",
    "    plt.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the cloud network architecture\n",
    "batch_size = 2 # for debug\n",
    "\n",
    "class cloudNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(cloudNN, self).__init__()\n",
    "        hidden_dim = 250\n",
    "        # first set layer\n",
    "        # COMPLETE HERE\n",
    "        \n",
    "        # second set layer\n",
    "        # COMPLETE HERE\n",
    "        \n",
    "        # classification layer\n",
    "        # COMPLETE HERE\n",
    "        \n",
    "    def forward(self, x): \n",
    "        # first set layer\n",
    "        # COMPLETE HERE\n",
    "        \n",
    "        # second set layer\n",
    "        # COMPLETE HERE\n",
    "        \n",
    "        # classification layer\n",
    "        # COMPLETE HERE\n",
    "        \n",
    "        return scores_cloud_class\n",
    "    \n",
    "# Instantiate the network\n",
    "net = cloudNN()\n",
    "net = net.to(device)\n",
    "print(net)\n",
    "utils.display_num_param(net) \n",
    "\n",
    "# Test the forward pass, backward pass and gradient update with a single batch\n",
    "init_lr = 0.001\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=init_lr)\n",
    "batch_images, batch_points, batch_labels = generate_batch_data(im_size, ob_size, batch_size, nb_points, nb_object_classes)\n",
    "optimizer.zero_grad()\n",
    "scores_cloud_class = net(batch_points) # [batch_size, nb_object_classes] = [2, 5]\n",
    "batch_labels = batch_labels.long() # [batch_size] = [2]\n",
    "# loss\n",
    "loss = nn.CrossEntropyLoss()(scores_cloud_class, batch_labels)\n",
    "loss.backward()\n",
    "optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "net = cloudNN()\n",
    "net = net.to(device)\n",
    "utils.display_num_param(net) \n",
    "\n",
    "# Optimizer\n",
    "init_lr = 0.001\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=init_lr)\n",
    "\n",
    "# Number of mini-batches per epoch\n",
    "nb_batch = 10\n",
    "batch_size = 10\n",
    "\n",
    "start=time.time()\n",
    "for epoch in range(10):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for _ in range(nb_batch):\n",
    "        \n",
    "        # FORWARD AND BACKWARD PASS\n",
    "        batch_images, batch_points, batch_labels = generate_batch_data(im_size, ob_size, batch_size, nb_points, nb_object_classes)\n",
    "        optimizer.zero_grad()\n",
    "        scores_cloud_class = net(batch_points) # [batch_size, nb_object_classes] = [2, 5]\n",
    "        batch_labels = batch_labels.long() # [batch_size] = [2]\n",
    "        # loss\n",
    "        loss = nn.CrossEntropyLoss()(scores_cloud_class, batch_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # COMPUTE STATS\n",
    "        running_loss += loss.detach().item()\n",
    "        num_batches += 1        \n",
    "    \n",
    "    # AVERAGE STATS THEN DISPLAY\n",
    "    total_loss = running_loss/num_batches\n",
    "    elapsed = (time.time()-start)/60\n",
    "    print('epoch=',epoch, '\\t time=', elapsed,'min', '\\t lr=', init_lr  ,'\\t loss=', total_loss )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Test time\n",
    "\n",
    "# select a batch of 2 images\n",
    "batch_size = 5\n",
    "\n",
    "# generate the batch of 2 images\n",
    "batch_images, batch_points, batch_labels = generate_batch_data(im_size, ob_size, batch_size, nb_points, nb_object_classes)\n",
    "        \n",
    "# forward pass\n",
    "scores_cloud_class = net(batch_points) # [batch_size, nb_object_classes]\n",
    "\n",
    "# class prediction\n",
    "pred_cloud_class = torch.argmax(scores_cloud_class, dim=1) # [batch_size] \n",
    "\n",
    "# Plot the ground truth solution and the predicted solution\n",
    "for b in range(batch_size):\n",
    "\n",
    "    #plt.imshow(batch_images[b,:,:], cmap='gray')\n",
    "    plt.imshow(torch.zeros(im_size,im_size), cmap='gray')\n",
    "    color, legend = obj_legend(batch_labels[b])\n",
    "    plt.scatter(batch_points[b,:,1],batch_points[b,:,0],marker='+',color=color,label=legend)\n",
    "    plt.legend(loc='best')\n",
    "    plt.colorbar()\n",
    "    plt.title('Ground Truth')\n",
    "    plt.show() \n",
    "    \n",
    "    #plt.imshow(batch_images[b,:,:], cmap='gray')\n",
    "    plt.imshow(torch.zeros(im_size,im_size), cmap='gray')\n",
    "    color, legend = obj_legend(pred_cloud_class[b])\n",
    "    plt.scatter(batch_points[b,:,1],batch_points[b,:,0],marker='+',color=color,label=legend)\n",
    "    plt.legend(loc='best')\n",
    "    plt.colorbar()\n",
    "    plt.title('Prediction')\n",
    "    plt.show() \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
